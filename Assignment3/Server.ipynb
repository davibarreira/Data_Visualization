{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "060e3f70-a0b1-4bb7-8b5f-d91b7b0160d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "96a43529-1be2-4830-84d7-9933deefe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import flask\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from flask import Flask\n",
    "from flask_cors import CORS\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "31efc2e7-dcc8-4229-814e-d5b21ae2c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Flask app\n",
    "app = Flask(__name__)\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
    "CORS(app)\n",
    "\n",
    "# TODO load all of the data generated from preprocessing\n",
    "qt = torch.load('./static/qt.pt')\n",
    "tensor2_3 = torch.load('./static/tensor2_3.pt')\n",
    "tensor2_3 = torch.nan_to_num(tensor2_3,nan=0.0) # Ajustando casos nan\n",
    "\n",
    "tensor3_4 = torch.load('./static/tensor3_4.pt')\n",
    "tensor3_4 = torch.nan_to_num(tensor3_4,nan=0.0) #  Ajustando casos nan\n",
    "\n",
    "s23 = tensor2_3.sum(dim=0)\n",
    "s34 = tensor3_4.sum(dim=0)\n",
    "\n",
    "act3 = torch.load('./static/act3.pt')\n",
    "images = []\n",
    "for i in range(0,20):\n",
    "    images.append(Image.open('./static/image'+str(i)+'.jpeg'))\n",
    "\n",
    "# number of clusters - feel free to adjust\n",
    "n_clusters = 9\n",
    "\n",
    "# these variables will contain the clustering of channels for the different layers\n",
    "a2_clustering,a3_clustering,a4_clustering = None,None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8dca3087-2eea-4710-8de6-0cce80abe512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_activation(clustering1,clustering2, tensor,n_clusters):\n",
    "    corr = []\n",
    "    n      = 0\n",
    "    for h in range(n_clusters):\n",
    "        for l in range(n_clusters):\n",
    "            c1_index = np.where(clustering1==h)[0]\n",
    "            c2_index = np.where(clustering2==l)[0]\n",
    "            corr.append(0)\n",
    "            Z = tensor.shape[0] * sum(clustering1==h) * sum(clustering2==l)\n",
    "            for j in c1_index:\n",
    "                for k in c2_index:\n",
    "                    corr[n] += tensor[:,j,k].sum()\n",
    "            corr[n] = corr[n]/Z\n",
    "            n+=1\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "703d2418-5030-4910-ac67-33b642038295",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_clustering,a3_clustering,a4_clustering = multiway_spectral_clustering(s23,s34,n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2e8b84dd-92a9-4bb5-8ece-006dc2d656a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr23 = correlations_activation(a2_clustering,a3_clustering,tensor2_3,n_clusters)\n",
    "corr34 = correlations_activation(a3_clustering,a4_clustering,tensor3_4,n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "acef68df-8661-4d10-a55a-c2efd728de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr23 = [i.item() for i in corr23]\n",
    "corr34 = [i.item() for i in corr34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "de06054c-8324-47ca-a973-400c31236711",
   "metadata": {},
   "outputs": [],
   "source": [
    "cline23 = []\n",
    "cline34 = []\n",
    "for h in list(itertools.combinations(range(n_clusters),2)):\n",
    "    cline23.append((h[0],h[1]))\n",
    "    cline34.append((h[0],h[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7cc22f21-a808-4fe9-8c00-2c6da943662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines23 = pd.DataFrame(cline23,columns=[\"layer2_cluster\",\"layer3_cluster\"])\n",
    "lines23[\"corr\"] = corr23\n",
    "lines34 = pd.DataFrame(cline34,columns=[\"layer3_cluster\",\"layer4_cluster\"])\n",
    "lines34[\"corr\"] = corr34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8ac8606c-e534-4207-9719-1c5b925c797a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"layer3_cluster\":0,\"layer4_cluster\":1,\"corr\":0.1883001328},{\"layer3_cluster\":0,\"layer4_cluster\":2,\"corr\":0.1530971527},{\"layer3_cluster\":0,\"layer4_cluster\":3,\"corr\":0.1728162169},{\"layer3_cluster\":0,\"layer4_cluster\":4,\"corr\":0.1928671896},{\"layer3_cluster\":0,\"layer4_cluster\":5,\"corr\":0.1591944695},{\"layer3_cluster\":0,\"layer4_cluster\":6,\"corr\":0.1715958267},{\"layer3_cluster\":0,\"layer4_cluster\":7,\"corr\":0.1734960675},{\"layer3_cluster\":0,\"layer4_cluster\":8,\"corr\":0.1423484832},{\"layer3_cluster\":1,\"layer4_cluster\":2,\"corr\":0.1936108023},{\"layer3_cluster\":1,\"layer4_cluster\":3,\"corr\":0.1716564894},{\"layer3_cluster\":1,\"layer4_cluster\":4,\"corr\":0.1498661637},{\"layer3_cluster\":1,\"layer4_cluster\":5,\"corr\":0.184050709},{\"layer3_cluster\":1,\"layer4_cluster\":6,\"corr\":0.1760363579},{\"layer3_cluster\":1,\"layer4_cluster\":7,\"corr\":0.1600677669},{\"layer3_cluster\":1,\"layer4_cluster\":8,\"corr\":0.2210408151},{\"layer3_cluster\":2,\"layer4_cluster\":3,\"corr\":0.1890523881},{\"layer3_cluster\":2,\"layer4_cluster\":4,\"corr\":0.2613182366},{\"layer3_cluster\":2,\"layer4_cluster\":5,\"corr\":0.1528018862},{\"layer3_cluster\":2,\"layer4_cluster\":6,\"corr\":0.1797076017},{\"layer3_cluster\":2,\"layer4_cluster\":7,\"corr\":0.1987224519},{\"layer3_cluster\":2,\"layer4_cluster\":8,\"corr\":0.0927099138},{\"layer3_cluster\":3,\"layer4_cluster\":4,\"corr\":0.1653264165},{\"layer3_cluster\":3,\"layer4_cluster\":5,\"corr\":0.1757068634},{\"layer3_cluster\":3,\"layer4_cluster\":6,\"corr\":0.1787275374},{\"layer3_cluster\":3,\"layer4_cluster\":7,\"corr\":0.1686441153},{\"layer3_cluster\":3,\"layer4_cluster\":8,\"corr\":0.1832397729},{\"layer3_cluster\":4,\"layer4_cluster\":5,\"corr\":0.1692394018},{\"layer3_cluster\":4,\"layer4_cluster\":6,\"corr\":0.179408893},{\"layer3_cluster\":4,\"layer4_cluster\":7,\"corr\":0.1814065129},{\"layer3_cluster\":4,\"layer4_cluster\":8,\"corr\":0.1381179988},{\"layer3_cluster\":5,\"layer4_cluster\":6,\"corr\":0.1684554815},{\"layer3_cluster\":5,\"layer4_cluster\":7,\"corr\":0.1611778885},{\"layer3_cluster\":5,\"layer4_cluster\":8,\"corr\":0.1925611645},{\"layer3_cluster\":6,\"layer4_cluster\":7,\"corr\":0.1680133492},{\"layer3_cluster\":6,\"layer4_cluster\":8,\"corr\":0.16664505},{\"layer3_cluster\":7,\"layer4_cluster\":8,\"corr\":0.2892556489}]'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines34.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b973bfc1-0e2d-4732-b51e-d3fd436f9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "\n",
    "Implement spectral clustering, given an affinity matrix. You are required to implement this using standard matrix computation libraries, e.g. numpy, for computing a spectral embedding.\n",
    "You may use k-means once you've obtained the spectral embedding.\n",
    "\n",
    "NOTE: the affinity matrix should _not_ be symmetric! Nevertheless, eigenvectors will be real, up to numerical precision - so you should cast to real numbers (e.g. np.real).\n",
    "'''\n",
    "def spectral_clustering(affinity_mat, n_clusters):\n",
    "    # code based on https://towardsdatascience.com/spectral-clustering-aba2640c0d5b\n",
    "    # diagonal matrix\n",
    "    D = torch.diag(torch.sum(affinity_mat,dim=1))\n",
    "\n",
    "    # graph laplacian\n",
    "    L = torch.pow(torch.inverse(D),1/2) @ affinity_mat @ torch.pow(D,1/2)\n",
    "\n",
    "    # eigenvalues and eigenvectors\n",
    "    vals, vecs = torch.eig(L,eigenvectors=True)\n",
    "    vals = vals[:,0]\n",
    "    # sort these based on the eigenvalues\n",
    "    vals = vals[torch.argsort(vals,descending=True)]\n",
    "    vecs = vecs[:,torch.argsort(vals,descending=True)]\n",
    "    row_norms = torch.norm(vecs[:,0:2],dim=1).unsqueeze(1).repeat(1,2)\n",
    "\n",
    "    Y = vecs[:,0:2]/row_norms\n",
    "    \n",
    "    # kmeans on first three vectors with nonzero eigenvalues\n",
    "    kmeans = KMeans(n_clusters=n_clusters,random_state=7)\n",
    "    kmeans.fit(Y[:,1:n_clusters])\n",
    "    labels = kmeans.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48c68e3-f8ba-4b8c-a0b8-15fb758bdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "\n",
    "Cluster the channels within each layer.\n",
    "This should take, as arguments, the two similarity matrices derived from the IoU scores.\n",
    "Specifically, the first argument is the similarity matrix between channels at layer 2 and channels at layer 3.\n",
    "The second argument is the similarity matrix between channels at layer 3 and channels at layer 4.\n",
    "\n",
    "A generalization of spectral biclustering should be performed. More details given in the assignment notebook.\n",
    "'''\n",
    "def multiway_spectral_clustering(s23, s34, n_clusters):\n",
    "\n",
    "    c23 = torch.diag(s23.sum(dim=0))\n",
    "    r23 = torch.diag(s23.sum(dim=1))\n",
    "\n",
    "    c34 = torch.diag(s34.sum(dim=0))\n",
    "    r34 = torch.diag(s34.sum(dim=1))\n",
    "\n",
    "    s2  = torch.inverse(r23) @ s23 @ torch.transpose(s23 @ torch.inverse(c23),0,1)\n",
    "    s4  = torch.transpose(s34 @ torch.inverse(c34),0,1) @ torch.inverse(r34) @ s34 \n",
    "    s3  = torch.transpose(s23 @ torch.inverse(c23),0,1) @ torch.inverse(r23) @ s23 \\\n",
    "            + torch.inverse(r34) @ s34 @ torch.transpose(s34 @ torch.inverse(c34),0,1)\n",
    "    \n",
    "    c2 = spectral_clustering(s2,n_clusters)\n",
    "    c3 = spectral_clustering(s3,n_clusters)\n",
    "    c4 = spectral_clustering(s4,n_clusters)\n",
    "    \n",
    "    return c2, c3, c4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0b0effb2-09b2-4069-b924-724fa338f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Do not cache images on browser, see: https://stackoverflow.com/questions/34066804/disabling-caching-in-flask\n",
    "'''\n",
    "@app.after_request\n",
    "def add_header(r):\n",
    "    r.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n",
    "    r.headers['Pragma'] = 'no-cache'\n",
    "    r.headers['Expires'] = '0'\n",
    "    r.headers['Cache-Control'] = 'public, max-age=0'\n",
    "    return r\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Given a link selected from the visualization, namely the layer and clusters at the individual layers, this route should compute the \n",
    "mean correlation from all channels in the source layer and all channels in the target layer, for each sample.\n",
    "'''\n",
    "@app.route('/link_score', methods=['GET','POST'])\n",
    "def link_score():\n",
    "    pass\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Given a layer (of your choosing), perform max-pooling over space, giving a vector of activations over channels for each sample. Perform UMAP to compute a 2D projection.\n",
    "'''\n",
    "@app.route('/channel_dr', methods=['GET','POST'])\n",
    "def channel_dr():\n",
    "    pass\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Compute correlation strength over selected instances, those brushed by the user.\n",
    "'''\n",
    "@app.route('/selected_correlation', methods=['GET','POST'])\n",
    "def selected_correlation():\n",
    "    pass\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Compute correlation strength over all instances.\n",
    "'''\n",
    "@app.route('/activation_correlation_clustering', methods=['GET'])\n",
    "def activation_correlation_clustering():\n",
    "    pass\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "In the main, before running the server, run clustering, store results in variables a2_clustering, a3_clustering, a4_clustering\n",
    "'''\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    a2_clustering,a3_clustering,a4_clustering = multiway_spectral_clustering(s23,s34,n_clusters)\n",
    "    \n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1c138-2376-4f19-a069-9fb6bca8d586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
