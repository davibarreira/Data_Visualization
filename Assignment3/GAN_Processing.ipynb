{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2646e6c5-ec90-4398-9e84-2c9921f8f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0565a9d6-351f-4e59-ad7a-e386cb053c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import MODEL_ZOO\n",
    "from models import build_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cefa3e0-0606-4b79-9433-023b8bd0178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b719b2-8f43-42ad-9c37-44af1da427ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have CUDA-enabled GPU, set this to True!\n",
    "is_cuda = False\n",
    "\n",
    "# StyleGAN tower\n",
    "model_name = 'stylegan_tower256'\n",
    "model_config = MODEL_ZOO[model_name].copy()\n",
    "url = model_config.pop('url')  # URL to download model if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fd73fd-a183-400c-8573-9da3e7b86148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "generator = build_generator(**model_config)\n",
    "\n",
    "# load the weights of the generator\n",
    "checkpoint_path = os.path.join('checkpoints', model_name+'.pth')\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "if 'generator_smooth' in checkpoint:\n",
    "    generator.load_state_dict(checkpoint['generator_smooth'])\n",
    "else:\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "if is_cuda:\n",
    "    generator = generator.cuda()\n",
    "generator.eval()\n",
    "\n",
    "'''\n",
    "This draws a sample from the StyleGAN generator.\n",
    "First we sample a random latent code.\n",
    "Then we feed this through a generator neural network, producing a 3-channel RGB image, as well as activations at early layers.\n",
    "In particular:\n",
    "* `act2` are activations at layer 2 (0-indexing used here), giving us an 512x8x8 tensor of activations, e.g. 512 channels, 8x8 spatial resolution\n",
    "* `act3` are activations at layer 3, giving us another 512x8x8 tensor of activations.\n",
    "* `act3_up` is the result of bilinear upsampling of `act3` to a 512x16x16 tensor.\n",
    "* `act4` are activations at layer 4, giving us a 512x16x16 tensor of activations.\n",
    "'''\n",
    "def sample_generator():\n",
    "    code = torch.randn(1,generator.z_space_dim)\n",
    "    if is_cuda:\n",
    "        code = code.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # truncated normal distribution, no random noise in style layers!\n",
    "        gen_out =  generator(code, trunc_psi=0.7,trunc_layers=8,randomize_noise=False)\n",
    "\n",
    "        act2 = gen_out['act2'][0].detach()\n",
    "        act3 = gen_out['act3'][0].detach()\n",
    "        act3_up = torch.nn.functional.interpolate(act3.unsqueeze(0),scale_factor=2,mode='bilinear',align_corners=True)[0]\n",
    "        act4 = gen_out['act4'][0].detach()\n",
    "\n",
    "        image = gen_out['image'][0].detach()\n",
    "    #\n",
    "\n",
    "    return act2,act3,act3_up,act4,image\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e52581-640d-4b3c-8ea7-2942f3050d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Postprocess images from the generator network - suitable to write to disk via PIL.\n",
    "'''\n",
    "def postprocess(images):\n",
    "    scaled_images = (images+1)/2\n",
    "    np_images = 255*scaled_images.numpy()\n",
    "    np_images = np.clip(np_images + 0.5, 0, 255).astype(np.uint8)\n",
    "    np_images = np_images.transpose(0, 2, 3, 1)\n",
    "    return np_images\n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Compute the Intersection-over-Union score between all pairs of channel activations for the provided tensors.\n",
    "The tensors should be of the same spatial resolution. Further, the tensors should be comprised of values 0 or 1, derived from quantile-based thresholding.\n",
    "This should return a tensor of shape (channel x channel)\n",
    "\n",
    "NOTE: this can be done with a few lines of code using broadcasting! (no loops necessary)\n",
    "'''\n",
    "def iou(a_i,a_j):\n",
    "    iou = torch.zeros(a_i.shape[0],512,512)\n",
    "    for s in range(0,a_i.shape[0]):\n",
    "        for i in range(0,a_i.shape[1]):\n",
    "            for j in range(i,a_j.shape[1]):\n",
    "                tsum = a_i[s][i] + a_j[s][j]\n",
    "                iou[s,i,j] = torch.sum(tsum>1)/torch.sum(tsum>0)\n",
    "                iou[s,j,i] = iou[s,i,j]\n",
    "                \n",
    "    return iou\n",
    "    \n",
    "#\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Given a tensor of activations (n_samples x channels x x-resolution x y-resolution), compute the per-channel top quantile (defined by perc), and then threshold activations\n",
    "based on the quantile (perform this per channel)\n",
    "'''\n",
    "def threshold(acts,k=4):\n",
    "    tensor_list=[]\n",
    "    qt =[]\n",
    "    for i in range(0,acts.shape[1]):\n",
    "        q = torch.quantile(acts[:,i,:,:],1-1/k)\n",
    "        tensor_list.append((acts[:,i,:,:] > q).type(torch.uint8))\n",
    "        qt.append(q)\n",
    "    t = torch.stack(tensor_list)\n",
    "    qt=  torch.stack(qt)\n",
    "    return t.permute(1,0,2,3),qt\n",
    "\n",
    "'''\n",
    "TODO\n",
    "\n",
    "Preprocessing:\n",
    "    1. Generate a set of samples from the generator network (see sample_generator above).\n",
    "    2. Threshold channel activations at each layer.\n",
    "    3. Compute IoU scores, for each sample, between all pairs of channels from layer 2 to layer 3, and layer 3 to layer 4 -> should produce 2 tensors of shape (n_samples x channels x channels).\n",
    "    4. Postprocess images and write the images to disk.\n",
    "    5. Write out the threhsolded activations, and IoU score tensors, to disk.\n",
    "\n",
    "Write everything to the 'static' directory.\n",
    "'''\n",
    "if __name__=='__main__':\n",
    "    n_samples = 20\n",
    "#     samples = []\n",
    "    act2    = []\n",
    "    act3    = []\n",
    "    act3up  = []\n",
    "    act4    = []\n",
    "    images  = []\n",
    "    for i in range(0,n_samples):\n",
    "        sample = sample_generator()\n",
    "        act2.append(sample[0])\n",
    "        act3.append(sample[1])\n",
    "        act3up.append(sample[2])\n",
    "        act4.append(sample[3])\n",
    "        images.append(sample[4])\n",
    "        \n",
    "    act2   = torch.stack(act2)\n",
    "    act3   = torch.stack(act3)\n",
    "    act3up = torch.stack(act3up)\n",
    "    act4   = torch.stack(act4)\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    tact2,q2   = threshold(act2)\n",
    "    tact3,q3   = threshold(act3)\n",
    "    tact3up,q3up = threshold(act3up)\n",
    "    tact4,q4   = threshold(act4)\n",
    "    \n",
    "    \n",
    "    torch.save(act2,'./static/act2.pt')\n",
    "    torch.save(act3,'./static/act3.pt')\n",
    "    torch.save(act4,'./static/act4.pt')\n",
    "    \n",
    "    qt = torch.dstack((q2,q3,q3up,q4))[0]\n",
    "    torch.save(qt,'./static/qt.pt')\n",
    "    \n",
    "    iou2_3  = iou(tact2,tact3)\n",
    "    torch.save(iou2_3,'./static/tensor2_3.pt')\n",
    "    \n",
    "    iou3_4  = iou(tact3up,tact4)\n",
    "    torch.save(iou3_4,'./static/tensor3_4.pt')\n",
    "    \n",
    "    images = postprocess(images)\n",
    "    for i in range(0,n_samples):\n",
    "        im = Image.fromarray(images[i],\"RGB\")\n",
    "        im.save('./static/image'+str(i)+'.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed471f-94c7-4071-a58d-bfc25ec38d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
